{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector - PL - Features extraction for SVM & Dense model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this notebook](https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/classifier/final_classifier.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "import sys\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import fasttext\n",
    "from polyglot.text import Text\n",
    "import syllables as sylla\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'svm'\n",
    "dim = 10 if MODEL == 'svm' else 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poleval 2019 data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes pre:\n",
    "    0 - non-harmful\n",
    "    1 - cyberbullying\n",
    "    2 - hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hsd/Poleval2019/perfect_data.pkl'):\n",
    "    with open('hsd/Poleval2019/train_texts.txt', 'r') as f:\n",
    "        tweets = f.readlines()\n",
    "    with open('hsd/Poleval2019/test_texts.txt', 'r') as f:\n",
    "        tweets.extend(f.readlines())\n",
    "    \n",
    "    with open('hsd/Poleval2019/train_labels.txt', 'r') as f:\n",
    "        labels = f.readlines()\n",
    "    with open('hsd/Poleval2019/test_labels.txt', 'r') as f:\n",
    "        labels.extend(f.readlines())\n",
    "    \n",
    "    with open('hsd/Poleval2019/perfect_data.pkl', 'w') as f:\n",
    "        def chcl(c):\n",
    "            return 0 if c=='0\\r\\n' else 1\n",
    "        labels = list(map(chcl, labels))\n",
    "        pickle.dump((tweets, labels), f)\n",
    "else:\n",
    "    with open('hsd/Poleval2019/perfect_data.pkl', 'r') as f:\n",
    "        tweets, labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes post:\n",
    "    0 - no hate\n",
    "    1 - hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dla mnie faworytem do tytu\\xc5\\x82u b\\xc4\\x99dzie Cracovia. Zobaczymy, czy typ si\\xc4\\x99 sprawdzi.\\r\\n',\n",
       "  0),\n",
       " ('@anonymized_account @anonymized_account Brawo ty Daria kibic ma by\\xc4\\x87 na dobre i z\\xc5\\x82e\\r\\n',\n",
       "  0),\n",
       " ('@anonymized_account @anonymized_account Super, polski premier sk\\xc5\\x82ada kwiaty na grobach kolaborant\\xc3\\xb3w. Ale doczekali\\xc5\\x9bmy czas\\xc3\\xb3w.\\r\\n',\n",
       "  0),\n",
       " ('@anonymized_account @anonymized_account Musi. Innej drogi nie mamy.\\r\\n',\n",
       "  0),\n",
       " ('Odrzut natychmiastowy, kwa\\xc5\\x9bna mina, mam problem\\r\\n', 0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(tweets[:5], labels[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def pos(text):\n",
    "    import morfeusz2\n",
    "    morf = morfeusz2.Morfeusz()\n",
    "\n",
    "    analysis = morf.analyse(line)\n",
    "    \n",
    "    return [interp[2] for i, j, interp in analysis]\n",
    "    \n",
    "\n",
    "def pad_words(words, length):\n",
    "    if len(words) >= length:\n",
    "        return words[:length]\n",
    "    else:\n",
    "        additional = length - len(words)\n",
    "        return words + ['PUSTY']*additional\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sent_analysis = Text(tweet)\n",
    "    sentiment = {}\n",
    "    sentiment['neg_cnt'] = 0\n",
    "    sentiment['neu_cnt'] = 0\n",
    "    sentiment['pos_cnt'] = 0\n",
    "    for w in sent_analysis.words:\n",
    "        mapping = {-1: 'neg_cnt', 0: 'neu_cnt', 1: 'pos_cnt'}\n",
    "        try:\n",
    "            sentiment[mapping[w.polarity]] += 1\n",
    "        except ValueError, UnicodeError:\n",
    "            sentiment['neu_cnt'] += 1\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = sylla.estimate(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59, 1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)), 2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0 if \"rt\" in words else 1\n",
    "    features = [FKRA, FRE, syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words, num_unique_terms,\n",
    "                sentiment['neg_cnt'], sentiment['neu_cnt'], sentiment['pos_cnt'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised fastText wordtokens training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hsd/Poleval2019/fasttext.ft'):\n",
    "    with open('hsd/Poleval2019/fasttext.ft', 'a') as f:\n",
    "        for t, l in list(zip(tweets, labels)):\n",
    "            f.write('__label__{} {}\\n'.format(l, preprocess(t)))\n",
    "\n",
    "# load fasttext model or train & save if none\n",
    "if os.path.exists('hsd/Poleval2019/fasttext_{}.bin'.format(MODEL)):\n",
    "    ft_model = fasttext.load_model('hsd/Poleval2019/fasttext_{}.bin'.format(MODEL))\n",
    "else:\n",
    "    ft_model = fasttext.train_supervised('hsd/Poleval2019/fasttext.ft',\n",
    "                                         lr=0.5, epoch=50, wordNgrams=3, dim=dim)\n",
    "    ft_model.save_model('hsd/Poleval2019/fasttext_{}.bin'.format(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordtoken features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordtoken_fts(data):\n",
    "    \n",
    "    sentences_words = []\n",
    "    for d in tqdm(data):\n",
    "        sentence = preprocess(d)\n",
    "        sentences_words.append(sentence.split(' '))\n",
    "    \n",
    "    opt_length = int(np.median([len(sw) for sw in sentences_words]))\n",
    "    sentences_words = [pad_words(sw, opt_length) for sw in sentences_words]\n",
    "    \n",
    "    ft_vectors = []\n",
    "    for sw in tqdm(sentences_words):\n",
    "        ft_vector = []\n",
    "        for w in sw:\n",
    "            ft_vector.extend(ft_model[w])\n",
    "        ft_vectors.append(ft_vector)\n",
    "    \n",
    "    return ft_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8b1a417d6a4c679a053443d63e2b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11041), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10e6dcae4ac4606909631bb40dd8f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11041), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wordtoken_features = get_wordtoken_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.25972363,\n",
       " 0.6093256,\n",
       " 0.0930879,\n",
       " -0.15155588,\n",
       " -0.10487659,\n",
       " 0.06611673,\n",
       " 0.13856022,\n",
       " -0.04793478,\n",
       " 0.10335264,\n",
       " 0.16084248,\n",
       " -0.56134087,\n",
       " 0.8714383,\n",
       " 0.074199535,\n",
       " -0.19224817,\n",
       " 0.05787058,\n",
       " 0.028133845,\n",
       " 0.40526202,\n",
       " -0.21943921,\n",
       " 0.23110494,\n",
       " 0.4049238,\n",
       " -0.06258048,\n",
       " 0.05566072,\n",
       " -0.052368417,\n",
       " -0.06970625,\n",
       " -0.06115733,\n",
       " 0.016731113,\n",
       " -0.010257306,\n",
       " -0.04316763,\n",
       " 0.010475652,\n",
       " -0.0587221,\n",
       " -0.36280036,\n",
       " 0.79676443,\n",
       " 0.18718208,\n",
       " -0.27790293,\n",
       " 0.007267143,\n",
       " -0.07893273,\n",
       " 0.38540623,\n",
       " -0.073079444,\n",
       " 0.12955764,\n",
       " 0.26674655,\n",
       " -0.030550629,\n",
       " 0.07951717,\n",
       " 0.053388935,\n",
       " 0.06686291,\n",
       " -0.05846211,\n",
       " -0.05604955,\n",
       " 0.09254257,\n",
       " 0.06846073,\n",
       " -0.07168886,\n",
       " 0.118393034,\n",
       " -0.40160927,\n",
       " 0.7123825,\n",
       " 0.052546557,\n",
       " -0.23500583,\n",
       " -0.041932467,\n",
       " -0.021902254,\n",
       " 0.35851163,\n",
       " -0.15595633,\n",
       " 0.2748768,\n",
       " 0.29753724,\n",
       " -0.09069144,\n",
       " 0.0479362,\n",
       " 0.08462821,\n",
       " -0.0060301884,\n",
       " -0.06289325,\n",
       " -0.08564071,\n",
       " 0.09997467,\n",
       " 0.033521224,\n",
       " 0.0127636725,\n",
       " -0.0061767288,\n",
       " -0.10216817,\n",
       " -0.009165661,\n",
       " -0.06572169,\n",
       " 0.08442421,\n",
       " 0.047728498,\n",
       " 0.05004199,\n",
       " 0.040177766,\n",
       " -0.0058646156,\n",
       " 0.0012191687,\n",
       " -0.028162668,\n",
       " -0.40581086,\n",
       " 0.7990702,\n",
       " 0.03373406,\n",
       " -0.24803758,\n",
       " -0.052520618,\n",
       " -0.05522836,\n",
       " 0.31611595,\n",
       " -0.06473352,\n",
       " 0.3139478,\n",
       " 0.23982379,\n",
       " -0.060212515,\n",
       " -0.027888982,\n",
       " -0.05430372,\n",
       " 0.0003457139,\n",
       " 0.05400616,\n",
       " 0.07825665,\n",
       " 0.09376972,\n",
       " 0.039950304,\n",
       " 0.03706241,\n",
       " -0.01899703,\n",
       " -0.43019533,\n",
       " 0.5519805,\n",
       " 0.11942891,\n",
       " -0.10200941,\n",
       " -0.042694323,\n",
       " 0.01786329,\n",
       " 0.1630754,\n",
       " -0.084436014,\n",
       " 0.21702543,\n",
       " 0.2501929,\n",
       " 0.06101184,\n",
       " -0.024555555,\n",
       " -0.05279149,\n",
       " 0.0034524542,\n",
       " -0.09786098,\n",
       " -0.033084195,\n",
       " -0.03571944,\n",
       " -0.02639515,\n",
       " -0.07658348,\n",
       " -0.056083925,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordtoken_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised fastText wordtokens training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no morfeusz2 installed then save preprocessed tweets and load pos strings from outer source\n",
    "sentences = [preprocess(t) for t in tweets]\n",
    "with open('hsd/Poleval2019/preprocessed.pkl', 'w') as f:\n",
    "    pickle.dump(sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hsd/Poleval2019/fasttext_pos.ft'):\n",
    "    # only if morfeusz2 is installed\n",
    "    '''with open('hsd/Poleval2019/fasttext_pos.ft', 'a') as f:\n",
    "        for t, l in list(zip(tweets, labels)):\n",
    "            f.write('__label__{} {}\\n'.format(l, pos(t)))'''\n",
    "    # otherwise load pos strings from outer source\n",
    "    with open('hsd/Poleval2019/pos_sentences.pkl', 'r') as f:\n",
    "        pos_sentences = pickle.load(f)\n",
    "    with open('hsd/Poleval2019/fasttext_pos.ft', 'a') as f:\n",
    "        for ps, l in list(zip(pos_sentences, labels)):\n",
    "            f.write('__label__{} {}\\n'.format(l, ps))\n",
    "        \n",
    "\n",
    "# load fasttext pos model or train & save if none\n",
    "if os.path.exists('hsd/Poleval2019/fasttext_pos_{}.bin'.format(MODEL)):\n",
    "    ft_pos_model = fasttext.load_model('hsd/Poleval2019/fasttext_pos_{}.bin'.format(MODEL))\n",
    "else:\n",
    "    ft_pos_model = fasttext.train_supervised('hsd/Poleval2019/fasttext_pos.ft',\n",
    "                                             lr=0.5, epoch=50, wordNgrams=3, dim=dim)\n",
    "    ft_pos_model.save_model('hsd/Poleval2019/fasttext_pos_{}.bin'.format(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech (PoS) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_fts(data):\n",
    "    \n",
    "    # only if morfeusz2 is installed\n",
    "    '''pos_sentences = [pos(sentence) for sentence in tqdm(sentences)]'''\n",
    "    # otherwise load pos strings from outer source\n",
    "    with open('hsd/Poleval2019/pos_sentences.pkl', 'r') as f:\n",
    "        pos_sentences = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    pos_tags = []\n",
    "    for ps in pos_sentences:\n",
    "        pos_tags.append(ps.split(' '))\n",
    "    \n",
    "    opt_length = int(np.median([len(pt) for pt in pos_tags]))\n",
    "    pos_tags = [pad_words(pt, opt_length) for pt in pos_tags]\n",
    "    \n",
    "    ft_vectors = []\n",
    "    for pt in tqdm(pos_tags):\n",
    "        ft_vector = []\n",
    "        for t in pt:\n",
    "            ft_vector.extend(ft_pos_model[t])\n",
    "        ft_vectors.append(ft_vector)\n",
    "    \n",
    "    return ft_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5dfa9f0511432a8e9817e93ab82c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11041), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_features = get_pos_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.68847364,\n",
       " 1.2415278,\n",
       " 0.29382572,\n",
       " -0.93917364,\n",
       " 0.066950694,\n",
       " 0.30000833,\n",
       " -0.1931048,\n",
       " 0.52006835,\n",
       " 0.4964681,\n",
       " 0.58200437,\n",
       " -0.11428785,\n",
       " 0.025025072,\n",
       " 0.076467164,\n",
       " -0.10548172,\n",
       " -0.051385183,\n",
       " -0.19466363,\n",
       " 0.123377524,\n",
       " -0.11968064,\n",
       " -0.0775263,\n",
       " -0.10946142,\n",
       " -0.09061464,\n",
       " 0.08752341,\n",
       " 0.03792799,\n",
       " -0.2066791,\n",
       " -0.027338302,\n",
       " -0.015878374,\n",
       " 0.027957069,\n",
       " -0.033831187,\n",
       " 0.060454987,\n",
       " 0.015502732,\n",
       " -0.07118461,\n",
       " 0.14237219,\n",
       " 0.10834007,\n",
       " -0.05040214,\n",
       " -0.047159214,\n",
       " 0.11034108,\n",
       " 0.011591187,\n",
       " -0.0011767191,\n",
       " 0.14348975,\n",
       " 0.11537423,\n",
       " -0.08136844,\n",
       " 0.22632498,\n",
       " -0.032268047,\n",
       " -0.0692468,\n",
       " -0.019915791,\n",
       " 0.112384774,\n",
       " 0.03064721,\n",
       " 0.14133495,\n",
       " -0.033671804,\n",
       " 0.0579389,\n",
       " -0.093241684,\n",
       " 0.19488356,\n",
       " 0.0826606,\n",
       " -0.16631353,\n",
       " 0.060278412,\n",
       " 0.060881287,\n",
       " -0.015351265,\n",
       " 0.03486257,\n",
       " 0.011026373,\n",
       " 0.10180261,\n",
       " 0.18740678,\n",
       " -0.353895,\n",
       " -0.03661656,\n",
       " 0.33652523,\n",
       " -0.048303,\n",
       " -0.17948602,\n",
       " 0.1320285,\n",
       " -0.17392011,\n",
       " -0.16467643,\n",
       " -0.23173858,\n",
       " 0.07813326,\n",
       " -0.2308999,\n",
       " -0.04021206,\n",
       " 0.18715832,\n",
       " -0.05989604,\n",
       " -0.15878327,\n",
       " 0.13502721,\n",
       " -0.17837434,\n",
       " -0.16073929,\n",
       " -0.16585149,\n",
       " -0.1115042,\n",
       " 0.13146366,\n",
       " 0.081978254,\n",
       " -0.07523562,\n",
       " 0.11506793,\n",
       " 0.13535474,\n",
       " -0.09866074,\n",
       " 0.11549861,\n",
       " 0.1570857,\n",
       " 0.19803767,\n",
       " -0.06931917,\n",
       " 0.26408267,\n",
       " 0.059270818,\n",
       " -0.13139085,\n",
       " -0.06466265,\n",
       " 0.11830785,\n",
       " 0.034787208,\n",
       " 0.07580091,\n",
       " 0.0015604934,\n",
       " 0.14651914,\n",
       " -0.68847364,\n",
       " 1.2415278,\n",
       " 0.29382572,\n",
       " -0.93917364,\n",
       " 0.066950694,\n",
       " 0.30000833,\n",
       " -0.1931048,\n",
       " 0.52006835,\n",
       " 0.4964681,\n",
       " 0.58200437,\n",
       " 0.12348016,\n",
       " -0.15843572,\n",
       " -0.10705744,\n",
       " 0.14838755,\n",
       " 0.082402505,\n",
       " -0.029189505,\n",
       " 0.047012236,\n",
       " -0.07084201,\n",
       " -0.08511532,\n",
       " 0.052169494,\n",
       " -0.66884416,\n",
       " 1.0056051,\n",
       " 0.38894945,\n",
       " -0.61983496,\n",
       " -0.015623144,\n",
       " 0.3102584,\n",
       " -0.16448432,\n",
       " 0.29259408,\n",
       " 0.39311233,\n",
       " 0.4215415,\n",
       " -0.4704917,\n",
       " 0.6702132,\n",
       " 0.19514173,\n",
       " -0.3967151,\n",
       " -0.0354882,\n",
       " 0.20947635,\n",
       " -0.17137654,\n",
       " 0.2650144,\n",
       " 0.34077877,\n",
       " 0.4169056,\n",
       " 0.45609075,\n",
       " -0.4333791,\n",
       " 0.1001197,\n",
       " 0.30648935,\n",
       " 0.0016143518,\n",
       " 0.19330215,\n",
       " -0.15981813,\n",
       " 0.33091053,\n",
       " -0.08995228,\n",
       " 0.32523507,\n",
       " -0.5734818,\n",
       " 0.80411536,\n",
       " 0.26685843,\n",
       " -0.599622,\n",
       " 0.0495624,\n",
       " 0.19598694,\n",
       " -0.05168624,\n",
       " 0.28225285,\n",
       " 0.29445416,\n",
       " 0.3586196,\n",
       " 0.45609075,\n",
       " -0.4333791,\n",
       " 0.1001197,\n",
       " 0.30648935,\n",
       " 0.0016143518,\n",
       " 0.19330215,\n",
       " -0.15981813,\n",
       " 0.33091053,\n",
       " -0.08995228,\n",
       " 0.32523507,\n",
       " -0.09277542,\n",
       " -0.037828196,\n",
       " -0.13682498,\n",
       " 0.10773751,\n",
       " -0.10093521,\n",
       " 0.004906673,\n",
       " -0.047717486,\n",
       " -0.026024302,\n",
       " -0.02431468,\n",
       " 0.14129551,\n",
       " -0.09986538,\n",
       " 0.8945546,\n",
       " -0.13860425,\n",
       " 0.10649327,\n",
       " 0.022557503,\n",
       " -0.10956911,\n",
       " 0.04765921,\n",
       " -0.089271374,\n",
       " 0.16499907,\n",
       " -0.6210369,\n",
       " -0.349272,\n",
       " 0.62842125,\n",
       " 0.14630398,\n",
       " -0.1471197,\n",
       " 0.056915026,\n",
       " 0.08215606,\n",
       " -0.1137959,\n",
       " 0.1626847,\n",
       " 0.0939986,\n",
       " 0.23615482,\n",
       " 0.11504436,\n",
       " -0.21081366,\n",
       " -0.07050771,\n",
       " 0.3633376,\n",
       " -0.047562324,\n",
       " -0.17315635,\n",
       " -0.028828137,\n",
       " -0.12558155,\n",
       " -0.15491916,\n",
       " -0.4067623,\n",
       " -0.09986538,\n",
       " 0.8945546,\n",
       " -0.13860425,\n",
       " 0.10649327,\n",
       " 0.022557503,\n",
       " -0.10956911,\n",
       " 0.04765921,\n",
       " -0.089271374,\n",
       " 0.16499907,\n",
       " -0.6210369,\n",
       " 0.39240643,\n",
       " -0.515971,\n",
       " -0.21403131,\n",
       " 0.27101293,\n",
       " -0.123221524,\n",
       " -0.18498293,\n",
       " 0.027924156,\n",
       " -0.23721571,\n",
       " -0.07032914,\n",
       " -0.21572752,\n",
       " 0.45609075,\n",
       " -0.4333791,\n",
       " 0.1001197,\n",
       " 0.30648935,\n",
       " 0.0016143518,\n",
       " 0.19330215,\n",
       " -0.15981813,\n",
       " 0.33091053,\n",
       " -0.08995228,\n",
       " 0.32523507,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d002d0db87ac4f48b71003931753eb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11041), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"polyglot.detect.base\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "other_features = np.array([other_features(t) for t in tqdm(tweets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.7   ,  32.51  ,  23.    ,   1.9166,  82.    ,  83.    ,\n",
       "         12.    ,  12.    ,  12.    ,   0.    ,  15.    ,   0.    ,\n",
       "          0.    ,   0.    ,   0.    ,   1.    ],\n",
       "       [  4.8   ,  78.25  ,  14.    ,   1.4   ,  47.    ,  86.    ,\n",
       "         12.    ,  10.    ,  10.    ,   1.    ,  12.    ,   1.    ,\n",
       "          0.    ,   2.    ,   0.    ,   1.    ],\n",
       "       [ 14.4   ,  11.1   ,  24.    ,   2.1817,  92.    , 131.    ,\n",
       "         13.    ,  11.    ,  11.    ,   0.    ,  17.    ,   1.    ,\n",
       "          0.    ,   2.    ,   0.    ,   1.    ],\n",
       "       [  5.2   ,  66.41  ,   8.    ,   1.5999,  30.    ,  69.    ,\n",
       "          7.    ,   5.    ,   5.    ,   0.    ,  11.    ,   0.    ,\n",
       "          0.    ,   2.    ,   0.    ,   1.    ],\n",
       "       [ 12.3   ,  17.46  ,  13.    ,   2.1665,  49.    ,  50.    ,\n",
       "          6.    ,   6.    ,   6.    ,   1.    ,   6.    ,   1.    ,\n",
       "          0.    ,   0.    ,   0.    ,   1.    ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features and feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "features = np.concatenate([wordtoken_features, pos_features, other_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11041, 416)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = dir_archive('hsd/Poleval2019/X_y_{}'.format(MODEL), {'features': features, 'labels': labels}, serialized=True)\n",
    "archive.dump()\n",
    "del archive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
